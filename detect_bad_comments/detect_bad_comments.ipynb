{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем \n",
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv(r'C:\\Users\\Бегущий за пивом\\Documents\\шпаргалки\\comments_project\\toxic_comments.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токсичных комментариев 10% от всех.Перед лемматизацией нужно все слова привести к нижнему регистру и отчистить от лишних символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk_stopwords.words('english')\n",
    "type(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    #импортируем стоп-слова\n",
    "    stop_words = nltk_stopwords.words('english')\n",
    "    #в нижний регистр \n",
    "    text = text.lower()\n",
    "    #заменяем все символы на пробелы \n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    sentence = [w for w in word_list if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " data['clean_text'] = data['text'].apply(clear_text)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для правильной лемматизации используем аргумент lemmatize() указать правильный тег «part-of-speech» (POS-тег).В nltk для этого есть метод nltk.pos_tag(). Он принимает только список (список слов), даже если нужно передать только одно слово.nltk.pos_tag() возвращает кортеж с тегом POS. Ключевым моментом здесь является сопоставление POS-тегов NLTK с форматом, принятым лемматизатором wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для учета контекста \n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "#лемматизация \n",
    "def postag_lemm_text(text):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Бегущий за пивом\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['clean_text'].apply(postag_lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(r'D:\\data_set\\comm_lem.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень долго  лемматизирует,поэтому сохранил. В дальнейшем будем просто экспортировать готовый фаил "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r'D:\\data_set\\comm_lem.csv')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этом разделе:**\n",
    "* буквы переведены в нижний регистр, оставлена только латиница, удалены стоп-слова.\n",
    "* комментарии лемматизированы с учётом части речи (POS-тегов).\n",
    "* данные на всякий случай сохранены "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "clean_text    0\n",
       "lemm_text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=12345, shuffle=True)\n",
    "\n",
    "corpus = data['lemm_text']\n",
    "\n",
    "#для баланса классов указываем  stratify=data['toxic'].values\n",
    "features_train, features_test, target_train, target_test = train_test_split(corpus, data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=12345)\n",
    "\n",
    "\n",
    "#делаем векторы \n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_train = tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = tf_idf.transform(features_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с самой простой логистической регрессии.Посмотрим как долго и есть ли смысл искать гипперпараметры на моем ноутбуке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии: 0.753\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=12345)\n",
    "\n",
    "\n",
    "log_reg.f1 = cross_val_score(log_reg, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "\n",
    "print('f1 для логистической регрессии: %.3f' %(log_reg.f1.mean()) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока нормально, теперь попробуем с LGBMClassifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10316, number of negative: 91591\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.464442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 466799\n",
      "[LightGBM] [Info] Number of data points in the train set: 101907, number of used features: 8648\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 10334, number of negative: 91573\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 4.784417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 469130\n",
      "[LightGBM] [Info] Number of data points in the train set: 101907, number of used features: 8697\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 10322, number of negative: 91585\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.993623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 467819\n",
      "[LightGBM] [Info] Number of data points in the train set: 101907, number of used features: 8671\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 10422, number of negative: 91485\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.976569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 469358\n",
      "[LightGBM] [Info] Number of data points in the train set: 101907, number of used features: 8693\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 10398, number of negative: 91510\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.389349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 468272\n",
      "[LightGBM] [Info] Number of data points in the train set: 101908, number of used features: 8704\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "f1 for LGBMClassifier: 0.748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LGBM = LGBMClassifier(n_estimators=180, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=12345)\n",
    "\n",
    "\n",
    "\n",
    "LGBM.f1 = cross_val_score(LGBM, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "\n",
    "print('f1 for LGBMClassifier: %.3f' %(LGBM.f1.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "долговато как для 80 деревьев,даже использовать randomsearch не вижу смысла мое железо не потянет.Ну и лес на такое же количество деревьев "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest  = RandomForestClassifier(n_estimators = 180 ,max_depth = 6, \n",
    "                                 class_weight='balanced', random_state=12345,n_jobs=-1)\n",
    "\n",
    "forest.f1 = cross_val_score(forest, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "print('f1 for RandomForest: %.3f' %(forest.f1.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все очень плохо("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.752926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.748352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.343406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   models  f1-score\n",
       "0      LogisticRegression  0.752926\n",
       "1          LGBMClassifier  0.748352\n",
       "2  RandomForestClassifier  0.343406"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame([\n",
    "    ['LogisticRegression',log_reg.f1.mean()],\n",
    "    ['LGBMClassifier',LGBM.f1.mean()],\n",
    "    ['RandomForestClassifier',forest.f1.mean()]\n",
    "    ],\n",
    "                     columns=['models','f1-score'])\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7538461538461538\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(tf_idf_train, target_train)\n",
    "\n",
    "prediction= log_reg.predict(tf_idf_test)\n",
    "test_f1 = f1_score(target_test, prediction)\n",
    "print(test_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тесте f1-score = 0.753, преодолел порог."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Предобработали данные:\n",
    "  1. Отчистили комментарии от ненужных символов \n",
    "  2. произвели лемматизированы с учётом части речи (POS-тегов)\n",
    "  3. Разбили на тестовую и обучающую выборки \n",
    "* Произвели обучение трех моделей с использованием кросс-валидации:\n",
    "  1. LogisticRegression\t0.752926\n",
    "  2. LGBMClassifier\t0.748352\n",
    "  3. RandomForestClassifier\t0.343406\n",
    "* На тетовой выборке LogisticRegression перешла порог в 0,75 \n",
    "\n",
    "Возможно можно было достичь лучших результатов поискав гиперпараметры, LGBMClassifier на 180 деревьях учился 4 минуты,лемматизация производилась около 15,так что проект упирается в технические отграничения железа.Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Для нашей задачи хватило и логистической регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1438,
    "start_time": "2023-05-04T05:54:17.227Z"
   },
   {
    "duration": 3217,
    "start_time": "2023-05-04T05:54:18.667Z"
   },
   {
    "duration": 34,
    "start_time": "2023-05-04T05:54:21.886Z"
   },
   {
    "duration": 40,
    "start_time": "2023-05-04T05:54:21.922Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-04T05:54:21.964Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-04T05:54:21.975Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-04T05:54:21.984Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-04T05:54:21.996Z"
   },
   {
    "duration": 28518,
    "start_time": "2023-05-04T05:54:22.027Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-04T05:54:50.547Z"
   },
   {
    "duration": 459,
    "start_time": "2023-05-04T05:54:50.556Z"
   },
   {
    "duration": 501,
    "start_time": "2023-05-04T05:55:15.093Z"
   },
   {
    "duration": 679620,
    "start_time": "2023-05-04T05:55:18.533Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-04T06:06:55.304Z"
   },
   {
    "duration": 8634,
    "start_time": "2023-05-04T06:08:49.972Z"
   },
   {
    "duration": 7631,
    "start_time": "2023-05-04T06:09:31.842Z"
   },
   {
    "duration": 8871,
    "start_time": "2023-05-04T06:11:03.214Z"
   },
   {
    "duration": 8782,
    "start_time": "2023-05-04T06:11:30.369Z"
   },
   {
    "duration": 7864,
    "start_time": "2023-05-04T06:14:36.422Z"
   },
   {
    "duration": 8568,
    "start_time": "2023-05-04T06:15:27.486Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
